experiment:
  name: 'name'
  save_dir: '../../local/logs'
  seed: 1

data:
  name: 'MNIST'  # Options: ['MNIST', 'synth']
  path: '../../local/data'
  train_ratio: 0.8
  num_workers: 8
  latent_dim: 3  # Only for synthetic
  observed_dim: 784  # Only for synthetic
  n_dev_samples: 50000  # Only for synthetic
  n_test_samples: 10000  # Only for synthetic

model:
  name: 's_vae'
  latent_dim: 3
  kl_coeff: 1
  backbone:
    name: 'linear'  # Options: ['linear', 'conv']
    hidden_dims: !!python/list [32, 64]
    data_shape: !!python/tuple [1, 28, 28]

training:
  batch_size: 32
  max_epochs: 100
  optimizer:
    name: 'adam'
    lr: 0.01
  scheduler:
    name: 'plateau'
    mode: 'min'
    patience: 3
    factor: 0.1
    min_lr: 0.0000001
    monitor: 'train/loss'
  ckpt_callback:
    monitor: 'valid/loss'
    save_top_k: 5

gpu: 0



